{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Breast Cancer Diagnosis Using XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is from the UCI Machine Learning Repository, downloaded from Kaggle. Link [here](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)\n",
    "\n",
    "Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "a) **radius** (mean of distances from center to points on the perimeter)<br>\n",
    "b) **texture** (standard deviation of gray-scale values)<br>\n",
    "c) **perimeter**<br>\n",
    "d) **area**<br>\n",
    "e) **smoothness** (local variation in radius lengths)<br>\n",
    "f) **compactness** (perimeter^2 / area - 1.0)<br>\n",
    "g) **concavity** (severity of concave portions of the contour)<br>\n",
    "h) **concave points** (number of concave portions of the contour)<br>\n",
    "i) **symmetry**<br>\n",
    "j) **fractal dimension** (\"coastline approximation\" - 1)<br>\n",
    "\n",
    "The columns names ending with \"se\" or \"worst\" refer to the standard error or the maximum of that feature observed, respectively.\n",
    "\n",
    "The target column is the binary \"diagnosis\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "#### XGBClassifier\n",
    "    * Unscaled\n",
    "        Test accuracy: 0.9824\n",
    "        Recall: 0.95\n",
    "    * Scaled\n",
    "        Test accuracy: 0.9649\n",
    "        Recall: 0.95\n",
    "        \n",
    "    * Unscaled after dropping low-importance columns:\n",
    "        Test accuracy: 0.9649\n",
    "        Recall: 0.92\n",
    "    * Scaled after dropping low_importance columns:\n",
    "        Test accuracy: 0.9673\n",
    "        Recall: 0.95\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = pd.read_csv('breast_cancer.csv')\n",
    "\n",
    "cancer = cancer.drop(['Unnamed: 32', 'id'], axis = 1)\n",
    "\n",
    "diag_map = {'B':0, 'M': 1}\n",
    "\n",
    "cancer['diagnosis'] = cancer['diagnosis'].map(diag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cancer.drop('diagnosis', 1)\n",
    "y = cancer['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=-1)]: Done 504 tasks      | elapsed:   23.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { max_features } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 0.5, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:   24.2s finished\n"
     ]
    }
   ],
   "source": [
    "xgb_grid = {\n",
    "    \"learning_rate\": [0.01, 0.1, 0.5],\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"max_features\": [0.5, 0.7, 0.9],\n",
    "    \"subsample\": [0.7, 0.9],\n",
    "    \"max_depth\": [3, 5],\n",
    "}\n",
    "\n",
    "model_xgb_grid = GridSearchCV(XGBClassifier(), param_grid = xgb_grid, verbose = 1, n_jobs = -1)\n",
    "model_xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(model_xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:32] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { max_features } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Training Score: 1.0\n",
      "Test Score: 0.9824561403508771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        72\n",
      "           1       1.00      0.95      0.98        42\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.99      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "               Predicted Ben.  Predicted Mal.\n",
      "Actually Ben.              72               0\n",
      "Actually Mal.               2              40\n"
     ]
    }
   ],
   "source": [
    "model_xgb = XGBClassifier(learning_rate = 0.5, \n",
    "                          max_depth = 3, \n",
    "                          max_features = 0.5, \n",
    "                          n_estimators = 100,\n",
    "                         subsample = 0.9)\n",
    "model_xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = model_xgb.predict(X_test)\n",
    "\n",
    "confusion_df = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_xgb),\n",
    "    index=[\"Actually Ben.\", \"Actually Mal.\",],\n",
    "    columns=[\"Predicted Ben.\", \"Predicted Mal.\",],\n",
    ")\n",
    "\n",
    "\n",
    "print('Training Score: {}'.format(model_xgb.score(X_train, y_train)))\n",
    "print('Test Score: {}'.format(model_xgb.score(X_test, y_test)))\n",
    "\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>0.377811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>0.107975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>0.088973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>0.074238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>0.073565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>0.028169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concavity_mean</td>\n",
       "      <td>0.026674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area_se</td>\n",
       "      <td>0.024636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>0.024550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>0.023002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>0.017317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points_se</td>\n",
       "      <td>0.013660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter_se</td>\n",
       "      <td>0.012750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity_se</td>\n",
       "      <td>0.011514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius_se</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fractal_dimension_mean</td>\n",
       "      <td>0.009895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>0.008727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>symmetry_worst</td>\n",
       "      <td>0.008576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>0.008033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>0.007221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness_se</td>\n",
       "      <td>0.007124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness_se</td>\n",
       "      <td>0.006428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal_dimension_se</td>\n",
       "      <td>0.005907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>0.005743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry_se</td>\n",
       "      <td>0.005373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fractal_dimension_worst</td>\n",
       "      <td>0.004897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>0.003630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture_se</td>\n",
       "      <td>0.001978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>symmetry_mean</td>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feat  importance\n",
       "22          perimeter_worst    0.377811\n",
       "27     concave points_worst    0.107975\n",
       "20             radius_worst    0.088973\n",
       "23               area_worst    0.074238\n",
       "7       concave points_mean    0.073565\n",
       "1              texture_mean    0.028169\n",
       "6            concavity_mean    0.026674\n",
       "13                  area_se    0.024636\n",
       "3                 area_mean    0.024550\n",
       "21            texture_worst    0.023002\n",
       "26          concavity_worst    0.017317\n",
       "17        concave points_se    0.013660\n",
       "12             perimeter_se    0.012750\n",
       "16             concavity_se    0.011514\n",
       "10                radius_se    0.010754\n",
       "9    fractal_dimension_mean    0.009895\n",
       "25        compactness_worst    0.008727\n",
       "28           symmetry_worst    0.008576\n",
       "24         smoothness_worst    0.008033\n",
       "5          compactness_mean    0.007221\n",
       "14            smoothness_se    0.007124\n",
       "15           compactness_se    0.006428\n",
       "19     fractal_dimension_se    0.005907\n",
       "4           smoothness_mean    0.005743\n",
       "18              symmetry_se    0.005373\n",
       "29  fractal_dimension_worst    0.004897\n",
       "0               radius_mean    0.003630\n",
       "11               texture_se    0.001978\n",
       "8             symmetry_mean    0.000878\n",
       "2            perimeter_mean    0.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = model_xgb_grid.best_estimator_.feature_importances_\n",
    "im_df = pd.DataFrame({\"feat\": X_train.columns, \"importance\": importances})\n",
    "im_df.sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   16.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:07:53] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { max_features } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 0.5, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:   20.2s finished\n"
     ]
    }
   ],
   "source": [
    "model_xgb_grid_s = GridSearchCV(XGBClassifier(), param_grid = xgb_grid, verbose = 1, n_jobs = -1)\n",
    "model_xgb_grid_s.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(model_xgb_grid_s.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:11:34] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { max_featues } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Training Score: 1.0\n",
      "Test Score: 0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        72\n",
      "           1       0.95      0.95      0.95        42\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "               Predicted Ben.  Predicted Mal.\n",
      "Actually Ben.              70               2\n",
      "Actually Mal.               2              40\n"
     ]
    }
   ],
   "source": [
    "model_xgb_scale = XGBClassifier(learning_rate = 0.1, \n",
    "                          max_depth = 3, \n",
    "                          max_featues = 0.5, \n",
    "                          n_estimators = 100, \n",
    "                          subsample = 0.9)\n",
    "model_xgb_scale.fit(X_train_scaled, y_train)\n",
    "y_pred_xgb_s = model_xgb_scale.predict(X_test_scaled)\n",
    "\n",
    "confusion_df = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_xgb_s),\n",
    "    index=[\"Actually Ben.\", \"Actually Mal.\",],\n",
    "    columns=[\"Predicted Ben.\", \"Predicted Mal.\",],\n",
    ")\n",
    "\n",
    "print('Training Score: {}'.format(model_xgb_scale.score(X_train_scaled, y_train)))\n",
    "print('Test Score: {}'.format(model_xgb_scale.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(classification_report(y_test, y_pred_xgb_s))\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model is way overfit!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>perimeter_worst</td>\n",
       "      <td>0.377811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>concave points_worst</td>\n",
       "      <td>0.107975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>radius_worst</td>\n",
       "      <td>0.088973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>area_worst</td>\n",
       "      <td>0.074238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>concave points_mean</td>\n",
       "      <td>0.073565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>texture_mean</td>\n",
       "      <td>0.028169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>concavity_mean</td>\n",
       "      <td>0.026674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>area_se</td>\n",
       "      <td>0.024635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>area_mean</td>\n",
       "      <td>0.024550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>texture_worst</td>\n",
       "      <td>0.023002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>concavity_worst</td>\n",
       "      <td>0.017317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>concave points_se</td>\n",
       "      <td>0.013660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>perimeter_se</td>\n",
       "      <td>0.012750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>concavity_se</td>\n",
       "      <td>0.011514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>radius_se</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fractal_dimension_mean</td>\n",
       "      <td>0.009895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>compactness_worst</td>\n",
       "      <td>0.008727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>symmetry_worst</td>\n",
       "      <td>0.008576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>smoothness_worst</td>\n",
       "      <td>0.008034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>compactness_mean</td>\n",
       "      <td>0.007220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>smoothness_se</td>\n",
       "      <td>0.007124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>compactness_se</td>\n",
       "      <td>0.006428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fractal_dimension_se</td>\n",
       "      <td>0.005907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smoothness_mean</td>\n",
       "      <td>0.005744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>symmetry_se</td>\n",
       "      <td>0.005373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>fractal_dimension_worst</td>\n",
       "      <td>0.004897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>radius_mean</td>\n",
       "      <td>0.003630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>texture_se</td>\n",
       "      <td>0.001978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>symmetry_mean</td>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>perimeter_mean</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feat  importance\n",
       "22          perimeter_worst    0.377811\n",
       "27     concave points_worst    0.107975\n",
       "20             radius_worst    0.088973\n",
       "23               area_worst    0.074238\n",
       "7       concave points_mean    0.073565\n",
       "1              texture_mean    0.028169\n",
       "6            concavity_mean    0.026674\n",
       "13                  area_se    0.024635\n",
       "3                 area_mean    0.024550\n",
       "21            texture_worst    0.023002\n",
       "26          concavity_worst    0.017317\n",
       "17        concave points_se    0.013660\n",
       "12             perimeter_se    0.012750\n",
       "16             concavity_se    0.011514\n",
       "10                radius_se    0.010754\n",
       "9    fractal_dimension_mean    0.009895\n",
       "25        compactness_worst    0.008727\n",
       "28           symmetry_worst    0.008576\n",
       "24         smoothness_worst    0.008034\n",
       "5          compactness_mean    0.007220\n",
       "14            smoothness_se    0.007124\n",
       "15           compactness_se    0.006428\n",
       "19     fractal_dimension_se    0.005907\n",
       "4           smoothness_mean    0.005744\n",
       "18              symmetry_se    0.005373\n",
       "29  fractal_dimension_worst    0.004897\n",
       "0               radius_mean    0.003630\n",
       "11               texture_se    0.001978\n",
       "8             symmetry_mean    0.000878\n",
       "2            perimeter_mean    0.000000"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = model_xgb_grid_s.best_estimator_.feature_importances_\n",
    "im_df = pd.DataFrame({\"feat\": X_train.columns, \"importance\": importances})\n",
    "im_df.sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropping low-importance columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Threshold = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_dropped_u = cancer[['perimeter_worst','concave points_worst', 'diagnosis']]\n",
    "\n",
    "\n",
    "X = cancer_dropped_u.drop(columns = 'diagnosis')\n",
    "\n",
    "y = cancer_dropped_u['diagnosis']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    1.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:01:36] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { max_features } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "{'learning_rate': 0.01, 'max_depth': 3, 'max_features': 0.5, 'n_estimators': 150, 'subsample': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 533 out of 540 | elapsed:    7.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:    7.2s finished\n"
     ]
    }
   ],
   "source": [
    "xgb_grid = {\n",
    "    \"learning_rate\": [0.01, 0.1, 0.5],\n",
    "    \"n_estimators\": [50, 100, 150],\n",
    "    \"max_features\": [0.5, 0.7, 0.9],\n",
    "    \"subsample\": [0.7, 0.9],\n",
    "    \"max_depth\": [3, 5],\n",
    "}\n",
    "\n",
    "model_xgb_grid = GridSearchCV(XGBClassifier(), param_grid = xgb_grid, verbose = 1, n_jobs = -1)\n",
    "model_xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(model_xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:02:56] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { max_features } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Training Score: 0.9736263736263736\n",
      "Test Score: 0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        66\n",
      "           1       1.00      0.92      0.96        48\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n",
      "               Predicted Ben.  Predicted Mal.\n",
      "Actually Ben.              66               0\n",
      "Actually Mal.               4              44\n"
     ]
    }
   ],
   "source": [
    "model_xgb_op = XGBClassifier(learning_rate = 0.1, \n",
    "                          max_depth = 3, \n",
    "                          max_features = 0.5, \n",
    "                          n_estimators = 100, \n",
    "                          subsample = 0.9)\n",
    "model_xgb_op.fit(X_train, y_train)\n",
    "y_pred_xgb = model_xgb_op.predict(X_test)\n",
    "\n",
    "confusion_df = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_xgb),\n",
    "    index=[\"Actually Ben.\", \"Actually Mal.\",],\n",
    "    columns=[\"Predicted Ben.\", \"Predicted Mal.\",],\n",
    ")\n",
    "\n",
    "\n",
    "print('Training Score: {}'.format(model_xgb_op.score(X_train, y_train)))\n",
    "print('Test Score: {}'.format(model_xgb_op.score(X_test, y_test)))\n",
    "\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done 376 tasks      | elapsed:   17.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:09:27] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { max_features } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "{'learning_rate': 0.1, 'max_depth': 3, 'max_features': 0.5, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 540 out of 540 | elapsed:   21.4s finished\n"
     ]
    }
   ],
   "source": [
    "model_xgb_grid_s = GridSearchCV(XGBClassifier(), param_grid = xgb_grid, verbose = 1, n_jobs = -1)\n",
    "model_xgb_grid_s.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(model_xgb_grid_s.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:10:37] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { max_featues } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Training Score: 1.0\n",
      "Test Score: 0.9649122807017544\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        72\n",
      "           1       0.95      0.95      0.95        42\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n",
      "               Predicted Ben.  Predicted Mal.\n",
      "Actually Ben.              70               2\n",
      "Actually Mal.               2              40\n"
     ]
    }
   ],
   "source": [
    "model_xgb_scale_op = XGBClassifier(learning_rate = 0.1, \n",
    "                          max_depth = 3, \n",
    "                          max_featues = 0.5, \n",
    "                          n_estimators = 100, \n",
    "                          subsample = 0.9)\n",
    "model_xgb_scale_op.fit(X_train_scaled, y_train)\n",
    "y_pred_xgb_s = model_xgb_scale_op.predict(X_test_scaled)\n",
    "\n",
    "confusion_df = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred_xgb_s),\n",
    "    index=[\"Actually Ben.\", \"Actually Mal.\",],\n",
    "    columns=[\"Predicted Ben.\", \"Predicted Mal.\",],\n",
    ")\n",
    "\n",
    "print('Training Score: {}'.format(model_xgb_scale_op.score(X_train_scaled, y_train)))\n",
    "print('Test Score: {}'.format(model_xgb_scale_op.score(X_test_scaled, y_test)))\n",
    "\n",
    "print(classification_report(y_test, y_pred_xgb_s))\n",
    "print(confusion_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
